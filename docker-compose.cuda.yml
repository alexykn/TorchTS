name: torchts_cuda

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend.cuda
    ports:
      - "5005:5005"
    volumes:
      - ./data:/app/data
      - ./src/backend:/app/src/backend
    environment:
      - PYTHONUNBUFFERED=1
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MODEL_UNLOAD_TIMEOUT=300
      - MODEL_DEVICE=cuda
      - TORCHTS_DB_URL=sqlite:///data/torchts.db
      - LOG_LEVEL=INFO
      - FORCE_GC_AFTER_REQUEST=false
      - CLEAR_CUDA_CACHE=true
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all # alternatively, use `count: 1` for a single GPU
              capabilities: [gpu]

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    ports:
      - "5173:5173"
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
    environment:
      - VITE_API_BASE=http://localhost:5005
      - DOCKER_ENV=true
    depends_on:
      - backend
    restart: unless-stopped
