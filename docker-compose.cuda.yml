name: torchts_cuda

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend.cuda
    ports:
      - "5005:5005"
    volumes:
      - ./data:/app/data
      - ./src/backend:/app/src/backend
    environment:
      - PYTHONUNBUFFERED=1
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all  # alternatively, use `count: 1` for a single GPU
              capabilities: [gpu]

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    ports:
      - "5173:5173"
    volumes:
      - ./src/frontend/templates/vue/src:/app/src
      - ./src/frontend/templates/vue/public:/app/public
    environment:
      - VITE_API_BASE=http://backend:5005
      - DOCKER_ENV=true
    depends_on:
      - backend
    restart: unless-stopped 